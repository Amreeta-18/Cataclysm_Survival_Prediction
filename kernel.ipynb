{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n'''Import required modules.'''\nimport numpy as np               # For linear algebra\nimport pandas as pd              # For data manipulation # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt  # For 2D visualization\nimport seaborn as sns            \nimport missingno as mn           # For visualizing missing values.\nfrom scipy import stats          # For statistics\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "93f5e5f1b8d6dab66203d4131f95c12c3392589a"
      },
      "cell_type": "code",
      "source": "'''Customize visualization.'''\nplt.rcParams['figure.figsize'] = [18,2.5]  # Create all the figure size by this dimension\nplt.style.use('ggplot')                    # Use ggplot's style for plotting\nsns.set_style({'axes.grid' : False})       # Removes gridlines\n\n'''Displays markdown formatted output like bold, italic bold etc.'''\nfrom IPython.display import Markdown\ndef bold(string):\n    display(Markdown(string))\n\n'''Ignores deprecation warning.'''\ndef ignore_warnings():\n    import warnings\n    warnings.filterwarnings('ignore', category = DeprecationWarning)  ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "'''Read and preview the train data from csv file.'''\ntrain = pd.read_csv('../input/train.csv')\nbold('**My train data:**')\ndisplay(train.head())\n\n#'''Shape of the train data'''\n#bold('**Shape of the train data:**')\n#display(train.shape)\n\n'''Read and preview the test from csv file.'''\ntest = pd.read_csv('../input/test.csv')\nbold('**Our test data:**')\ndisplay(test.head())\n\n#'''Shape of the test data'''\n#bold('**Shape of the test data:**')\n#display(test.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1bc0e90f4ec6851dc550d7701577f091d9afdece"
      },
      "cell_type": "code",
      "source": "'''Merge train and test data together. This eliminates the hassle of handling train and test data seperately for various analysis.'''\nmerged = pd.concat([train, test], sort = False)\nbold('**Merged data:**')\ndisplay(merged.head())\n\n'''Shape of the combined data'''\nbold('**Shape of the merged data:**')\ndisplay(merged.shape)\n\n'''Variables in the combined data'''\nbold('**Name of the variables:**')\ndisplay(merged.columns)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d1671206b102e9e637953e980fdfa6fafbe720e2"
      },
      "cell_type": "code",
      "source": "'''Pandas data types for our different variables.'''\nbold('**Data types of our variables:**')\ndisplay(merged.dtypes)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c1695d766f1b50b9866af0e8068c615603f3979f"
      },
      "cell_type": "code",
      "source": "'''To analyse categorical variables, we will create three custom functions.\nThe first two functions displays bar labels in absolute and relative scale respectively. And the 3rd one creates a dataframe of absolute and relative and also generates abs and relative frequency plot for each variable.'''\n\n''' #1.Function for displaying bar labels in absolute scale.'''\ndef abs_bar_labels():\n    plt.ylabel('Absolute Frequency')\n    plt.xticks(rotation = 0)\n    plt.yticks([])\n    # Set individual bar lebels in absolute number\n    for x in ax.patches:\n        ax.annotate(x.get_height(), \n        (x.get_x() + x.get_width()/2., x.get_height()), ha = 'center', va = 'center', xytext = (0, 7), \n        textcoords = 'offset points', fontsize = 14, color = 'black')\n    \n        \n'''#2.Function for displaying bar lebels in relative scale.'''\ndef pct_bar_labels():\n    plt.ylabel('Relative Frequency (%)')\n    plt.xticks(rotation = 0)\n    plt.yticks([])   \n    # Set individual bar lebels in proportional scale\n    for x in ax1.patches:\n        ax1.annotate(str(x.get_height()) + '%', \n        (x.get_x() + x.get_width()/2., x.get_height()), ha = 'center', va = 'center', xytext = (0, 7), \n        textcoords = 'offset points', fontsize = 14, color = 'black')\n             \n'''#3.Function to create a dataframe of absolute and relative frequency of each variable. And plot absolute and relative frequency.'''\ndef absolute_and_relative_freq(variable):\n    global  ax, ax1 \n    # Dataframe of absolute and relative frequency\n    absolute_frequency = variable.value_counts()\n    # Will be multiplied by 100 and rounded to 2 decimal points for percentage\n    relative_frequency = round(variable.value_counts(normalize = True)*100, 2) \n    df = pd.DataFrame({'Absolute Frequency':absolute_frequency, 'Relative Frequency(%)':relative_frequency})\n    # This portion plots absolute frequency with bar labeled.\n    ax =  absolute_frequency.plot.bar()\n    plt.title('Absolute Frequency of %s' %variable.name) # Prints variable name as title in matplotlib\n    abs_bar_labels()  # Displays bar labels in abs scale.\n    plt.show()\n    # This portion plots relative frequency with bar labeled.\n    ax1 = relative_frequency.plot.bar()\n    plt.title('Relative Frequency of %s' %variable.name)\n    pct_bar_labels()\n    plt.show()\n    print('Absolute & Relative Frequency of',variable.name,':')\n    return display(df)\n         ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f685436f5962451f93e3693c6b73d86cd51963c3"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "633f9c84973772d0096328249989a85154aba71e"
      },
      "cell_type": "code",
      "source": "'''Plot and count the number of survivors and victims in absolute and relative scale in the tragedy.'''\nmerged.Survived.agg(absolute_and_relative_freq, axis = 0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "46ef5444add297d616106e9de4db22b06b6abe45"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9a9e7e5dedf7cc43ebd54f4285f76d33fa71c116"
      },
      "cell_type": "code",
      "source": "'''Plot and count the absolute and relative frequency of Sex.'''\nmerged.Sex.agg(absolute_and_relative_freq)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e2be5abde87646566d6bb712f04b343abdf5448f"
      },
      "cell_type": "code",
      "source": "'''Plot and count the absolute and relative frequency of Pclass.'''\nmerged.Pclass.agg(absolute_and_relative_freq)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "67c0754e5a2b565afebb683c735b2d9598b9b36e"
      },
      "cell_type": "code",
      "source": "'''Plot and count the absolute and relative frequency of Embarked.'''\nmerged.Embarked.agg(absolute_and_relative_freq)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a98dbafe215a566a741841eb627b21f9fa4df5c9"
      },
      "cell_type": "code",
      "source": "'''Absolute frequency of Cabin.'''\nabs_freq_cabin = merged.Cabin.value_counts(dropna = False)\nbold('**Categories of Cabin:**')\ndisplay(abs_freq_cabin.head())\n\n\"\"\"As frequency of Cabin isn't what we expected, let's count total categories in Cabin.\"\"\"\nbold('**Total categories in Cabin:**')\ndisplay(abs_freq_cabin.count())\n\n'''Finally preview the variable Cabin to see what is causing the irregularity.'''\nbold('**Preview Cabin:**')\ndisplay(merged.Cabin.head(7))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7a3e4b598ee7823f04b546b3bffa457ed93169bb"
      },
      "cell_type": "code",
      "source": "'''Count total categories in Name.'''\nbold('**Total categories in Name:**')\ndisplay(merged.Name.value_counts().count())\n\n\"\"\"Let's finally check the what's inside the variable Name.\"\"\"\nbold('**Preview Name:**')\ndisplay(merged.Name.head())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e9ae103f9c0e55f474b48cd63ba0e41b37bd30b2"
      },
      "cell_type": "code",
      "source": "'''Count total groups in variable Ticket.'''\nbold('**Total groups in Ticket:**')\ndisplay(merged.Ticket.value_counts().count())\n\n'''Lets investigate Ticket.'''\nbold('**Preview of Ticket:**')\ndisplay(merged.Ticket.head())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a4ee88e2a3ceb2ec4c8f810c1072cc84e61f2318"
      },
      "cell_type": "code",
      "source": "'''Plot and count the absolute and relative frequency of SibSp.'''\nmerged.SibSp.agg(absolute_and_relative_freq)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "52a150c213de06adf4fc9b9fbeb70d00d90ff043"
      },
      "cell_type": "code",
      "source": "'''Plot and count the absolute and relative frequency of Parch.'''\nmerged.Parch.agg(absolute_and_relative_freq)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "71e73994783361ec9fa9320931ae2bcc7aa3f063"
      },
      "cell_type": "code",
      "source": "'''To analyse numerical variables, we will create two custom functions.\nThe 1st one will calculate summary statistics and plot histogram for each numerical variable.\nAnd the 2nd function will plot kernel density plot and calculate skewness for each numerical variable.''' \n\n'''#1.Summary statistics with histogram'''\ndef summary_stats_and_hist(variable):\n    global ax\n    stats = variable.describe()\n    ax = variable.plot.hist()\n    plt.xlabel('%s' %variable.name)\n    plt.title('Distribution of %s with Histogram' %variable.name)\n    abs_bar_labels()\n    print('Summary Statistics of', variable.name, ':')\n    return display(stats)\n\n'''#2.Density plot with skewness.'''\ndef density_plot_and_skewness(variable):\n    variable.plot.hist(density = True)\n    variable.plot.kde(style = 'k--')\n    plt.xlabel('%s'%variable.name)\n    plt.title('Distribution of %s with Density Plot & Histogram' %variable.name)\n    print('Skewness of ', variable.name, ':')\n    skewness = variable.skew()\n    return display(skewness)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eedf13da859403e3d64c1218284a0b7765dcd88b"
      },
      "cell_type": "code",
      "source": "'''Calculate summary statistics of Fare with histogram.'''\nmerged.Fare.agg(summary_stats_and_hist)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6fb5b7832fdf17a284931338f7ed6bd1ab5b8653"
      },
      "cell_type": "code",
      "source": "'''Plot density plot of Fare and calculate skewness.'''\nmerged.Fare.agg(density_plot_and_skewness)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ca52cb2e642d668583734945582dc34b0fd54280"
      },
      "cell_type": "code",
      "source": "'''Calculate summary statistics of Age with histogram.'''\nmerged.Age.agg(summary_stats_and_hist)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f5919497610938f50d8c012721e0d9f07532e73a"
      },
      "cell_type": "code",
      "source": "'''Plot density plot of Age and calculate skewness.'''\nmerged.Age.agg(density_plot_and_skewness)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ce33d224ba652259f28852f15547c8f6f7bd0c11"
      },
      "cell_type": "code",
      "source": "'''What does passengerId contain?'''\ndisplay(merged.PassengerId.head())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d880aec580c9a859b2ee12bafabdd53970e2ad6f"
      },
      "cell_type": "code",
      "source": "\"\"\"Let's preview the Cabin again.\"\"\"\nbold('**Cabin preview:**')\ndisplay(merged.Cabin.head())\n\n\"\"\"It seems Cabin contains some missing values. Let's count them.\"\"\"\nbold('**Missing values in Cabin:**')\ndisplay(merged.Cabin.isnull().sum())\n\n'''Total categories in Cabin before processing.'''\nbold('**Total categories in Cabin before processing:**')\ndisplay(merged.Cabin.value_counts(dropna = False).count())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7f30e3326e6f8929959dfd5f45ba8f36bddc7f74"
      },
      "cell_type": "code",
      "source": "\"\"\"Flag all the NaNs of Cabin as 'X'.\"\"\"\nmerged.Cabin.fillna(value = 'X', inplace = True)\n\n'''Keep only the 1st character where Cabin is alphanumerical.'''\nmerged.Cabin = merged.Cabin.apply( lambda x : x[0])\ndisplay(merged.Cabin.value_counts())\n\n'''After processing, we can visualize the absolute and relative frequency of newly transformed Cabin variable.'''\nmerged.Cabin.agg(absolute_and_relative_freq)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b5130ae9234f50d3a5f631f16ee47792f2234c47"
      },
      "cell_type": "code",
      "source": "\"\"\"Lets see what's inside the Name.\"\"\"\ndisplay(merged.Name.head(8))\n\n'''Create a new variable Title that extracts titles from Name.'''\nmerged['Title'] = merged.Name.str.extract('([A-Za-z]+)\\.')\n\n'''Count the extracted categories of Title from Name.'''\ndisplay(merged.Title.value_counts())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a7418b1c5c201d4ef82bbd9c075ce9d6abc6dc12"
      },
      "cell_type": "code",
      "source": "'''Create a bucket Officer and put Dr, Rev, Col, Major, Capt titles into it.'''\nmerged.Title.replace(to_replace = ['Dr', 'Rev', 'Col', 'Major', 'Capt'], value = 'Officer', inplace = True)\n\n'''Put Dona, Jonkheer, Countess, Sir, Lady, Don in bucket Aristocrat.'''\nmerged.Title.replace(to_replace = ['Dona', 'Jonkheer', 'Countess', 'Sir', 'Lady', 'Don'], value = 'Aristocrat', inplace = True)\n\n'''Finally Replace Mlle and Ms with Miss. And Mme with Mrs.'''\nmerged.Title.replace({'Mlle':'Miss', 'Ms':'Miss', 'Mme':'Mrs'}, inplace = True)\n\n'''After processing, visualise and count absolute and relative frequency of transformed Title.'''\nmerged.Title.agg(absolute_and_relative_freq)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "343e3bdbd0abc338ff25dec14210138dbd8e5fec"
      },
      "cell_type": "code",
      "source": "'''Merge SibSp and Parch to create a variable Family_size.'''\nmerged['Family_size'] = merged.SibSp + merged.Parch + 1  # Adding 1 for single person\ndisplay(merged.Family_size.value_counts())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e41afc8cebe6133350e79ec2903d388d9393e5b1"
      },
      "cell_type": "code",
      "source": "'''Create buckets of single, small, medium, and large and then put respective values into them.'''\nmerged.Family_size.replace(to_replace = [1], value = 'single', inplace = True)\nmerged.Family_size.replace(to_replace = [2,3], value = 'small', inplace = True)\nmerged.Family_size.replace(to_replace = [4,5], value = 'medium', inplace = True)\nmerged.Family_size.replace(to_replace = [6, 7, 8, 11], value = 'large', inplace = True)\n\n'''After processing, visualise and count the absolute and relative frequency of engineered Family_size.'''\nmerged.Family_size.agg(absolute_and_relative_freq)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b72c8d5fdd27327be51666e8f10c2b1704b30e23"
      },
      "cell_type": "code",
      "source": "\"\"\"Let's preview the variable Ticket first.\"\"\"\ndisplay(merged.Ticket.head())\n\n'''Assign N if there is only number and no character. If there is a character, extract the character only.'''\nticket = []\nfor x in list(merged.Ticket):\n    if x.isdigit():\n        ticket.append('N')\n    else:\n        ticket.append(x.replace('.','').replace('/','').strip().split(' ')[0])\n        \n'''Swap values'''\nmerged.Ticket = ticket\n\n'''Count the categories in Ticket.'''\nbold('**Categories of Ticket:**')\ndisplay(merged.Ticket.value_counts())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "68c260c4bab6532445e8a78d73c698d7856395ef"
      },
      "cell_type": "code",
      "source": "'''Keep only the 1st character of Ticket to further reduce the Ticket categories.'''\nmerged.Ticket = merged.Ticket.apply(lambda x : x[0])\ndisplay(merged.Ticket.value_counts())\n\n'''After processing, visualise and count the absolute and relative frequency of updated Ticket.'''\nmerged.Ticket.agg(absolute_and_relative_freq)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e30028b432f2d470e95f40c6ef1b562c9fd33705"
      },
      "cell_type": "code",
      "source": "'''Create a function to count total outliers. And plot variables with and without outliers.'''\ndef outliers(variable):\n    # Calculate 1st, 3rd quartiles and iqr.\n    q1, q3 = variable.quantile(0.25), variable.quantile(0.75)\n    iqr = q3 - q1\n    \n    # Calculate lower fence and upper fence for outliers\n    l_fence, u_fence = q1 - 1.5*iqr , q3 + 1.5*iqr   # Any values less than l_fence and greater than u_fence are outliers.\n    \n    # Observations that are outliers\n    outliers = variable[(variable<l_fence) | (variable>u_fence)]\n    print('Total Outliers of', variable.name,':', outliers.count())\n    \n    # Drop obsevations that are outliers\n    filtered = variable.drop(outliers.index, axis = 0)\n\n    # Create subplots\n    fig, (ax1, ax2) = plt.subplots(2,1)\n    \n    # Gives space between two subplots\n    fig.subplots_adjust(hspace = 1) \n    \n     \n    # Plot variable with outliers\n    variable.plot.box(vert = False, color = 'coral', grid = False, ax = ax1, title = 'Distribution with Outliers for %s' %variable.name)\n\n    # Plot variable without outliers\n    filtered.plot.box(vert = False, color = 'coral', grid = False, ax = ax2, title = 'Distribution without Outliers for %s' %variable.name)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ba041b9463e16982af1909e423ff33f2af521fba"
      },
      "cell_type": "code",
      "source": "'''Count total outliers of Age. Plot Age with and without outliers.'''\nmerged.Age.agg(outliers)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "24b2fa0c439de3a2147a3cd522b3f685125262d0"
      },
      "cell_type": "code",
      "source": "'''Count total outliers of Fare. Plot Fare with and without outliers.'''\nmerged.Fare.agg(outliers)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d7f9c3b2aa50d6472aee3e50a887c0b6d629b8e6"
      },
      "cell_type": "code",
      "source": "'''We can visualize the missing values for each variable.'''\nmn.matrix(merged)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "610966a11c4968de07b920c4e5100b58410a6132"
      },
      "cell_type": "code",
      "source": "\"\"\"Let's count the missing values for each variable.\"\"\"\nbold('**Missing values for each variable:**')\ndisplay(merged.isnull().sum())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cb9c294ec361f3ec8d4b9ae8a8a3ae681cf1eb9e"
      },
      "cell_type": "code",
      "source": "'''Impute missing values of Embarked. Embarked is a categorical variable where S is the most frequent.'''\nmerged.Embarked.fillna(value = 'S', inplace = True)\n\n'''Impute missing values of Fare. Fare is a numerical variable with outliers. Hence it will be imputed by median.'''\nmerged.Fare.fillna(value = merged.Fare.median(), inplace = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ee330b6894ffdd0f80e8dbc5b8c0edf93a342e8d"
      },
      "cell_type": "code",
      "source": "\"\"\"Create a boxplot to view the variables correlated with Age. First take the variables we're interested in.\"\"\"\ncorrelation = merged.loc[:, ['Sex', 'Pclass', 'Embarked', 'Title', 'Family_size', 'Parch', 'SibSp', 'Cabin', 'Ticket']]\nfor columns in correlation:\n    plt.figure(columns)\n    sns.boxplot(x = columns, y = merged.Age, data = correlation)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c903e9dc23d7aab085212501725fdb50e175d618"
      },
      "cell_type": "code",
      "source": "\"\"\"Let's plot correlation heatmap to see which variable is highly correlated with Age and if our boxplot interpretation holds true. We need to convert categorical variable into numerical to plot correlation heatmap. So convert categorical variables into numerical.\"\"\"\n\nfrom sklearn.preprocessing import LabelEncoder\ncorrelation = correlation.agg(LabelEncoder().fit_transform)\ncorrelation['Age'] = merged.Age # Inserting Age in dataframe correlation\ncorrelation = correlation.set_index('Age').reset_index() # Move Age at index 0.\n\n'''Now create the heatmap correlation.'''\nsns.heatmap(correlation.corr(), cmap ='BrBG', annot = True)\nplt.title('Variables correlated with Age')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3b68dd54771cfaf2b31737f2bf26b9a86e4a81b1"
      },
      "cell_type": "code",
      "source": "'''Impute Age with median of respective columns (Title and Pclass).'''\nmerged.Age = merged.groupby(['Title', 'Pclass'])['Age'].transform(lambda x: x.fillna(x.median()))\n\n'''So by now we should have no variables with missing values.'''\nbold('**Missing values after imputation:**')\ndisplay(merged.isnull().sum())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "65e976589dbfaa8779df01b27c8d25834d3c024c"
      },
      "cell_type": "code",
      "source": "\"\"\"Let's split the train and test data for bivariate analysis since test data has no Survived values. We need our target variable without missing values to conduct the association test with predictor variables.\"\"\"\ndf_train = merged.iloc[:891, :]\ndf_test = merged.iloc[891:, :]\ndf_test = df_test.drop(columns = ['Survived'], axis = 1)\n\n'''#1.Create a function that creates boxplot between categorical and numerical variables and calculates biserial correlation.'''\ndef boxplot_and_correlation(cat,nume):\n    '''cat = categorical variable, and nume = numerical variable.'''\n    ax = sns.boxplot(x = cat, y = nume)\n    \n    # Select boxes to change the color\n    box = ax.artists[0]\n    box1 = ax.artists[1]\n    \n    # Change the appearance of that box\n    box.set_facecolor('red')\n    box1.set_facecolor('green')\n    \n    plt.title('Association between Survived & Fare %s' %nume.name)\n    print('Correlation between', nume.name, 'and', cat.name,':', stats.pointbiserialr(nume, cat))\n    plt.show()\n    return display(ax)\n\n'''#2.Create another function to calculate mean when grouped by categorical variable. And also plot the grouped mean.'''\ndef nume_grouped_by_cat(nume, cat):\n    global ax\n    grouped_by_cat = nume.groupby(cat).mean().sort_values( ascending = False)\n    grouped_by_cat.rename ({1:'survived', 0:'died'}, axis = 'rows', inplace = True) # Renaming index\n    grouped_by_cat = round(grouped_by_cat, 2)\n    ax = grouped_by_cat.plot.bar() \n    abs_bar_labels()\n    plt.ylabel('Mean %s' %nume.name)\n    plt.title('Survivors vs Victims Mean %s' %nume.name)\n    print('Mean', nume.name, 'of Survivors vs Victims:')\n    return display(grouped_by_cat)\n\n'''#3.This function plots histogram of numerical variable for every class of categorical variable.'''\ndef nume_hist_by_cat(nume,cat):\n    nume[cat == 1].hist(color = ['g'], grid = False)\n    nume[cat == 0].hist(color = ['r'], grid = False)\n    plt.yticks([])\n    plt.xlabel('%s' %nume.name)\n    plt.title('Survivors vs Victims Distribution of %s' %nume.name)\n    \n    '''#4.Create a function to calculate anova between numerical and categorical variable.'''\ndef anova(nume, cat):\n    from scipy import stats\n    grp_nume_by_cat_1 = nume[cat == 1] # Group our numerical variable by categorical variable(1). Group Fair by survivors\n    grp_nume_by_cat_0 = nume[cat == 0] # Group our numerical variable by categorical variable(0). Group Fare by victims\n    f_val, p_val = stats.f_oneway(grp_nume_by_cat_1, grp_nume_by_cat_0) # Calculate f statistics and p value\n    print('Anova results:', f_val, p_val)  \n    \n'''#5.Create another function that calculates Tukey's test between our nemurical and categorical variable.'''\ndef tukey_test(nume, cat):\n    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n    tukey = pairwise_tukeyhsd(endog = nume,  # Numerical data\n                             groups = cat,   # Categorical data\n                             alpha = 0.05)   # Significance level\n    \n    summary = tukey.summary()   # See test summary\n    return display(summary)   ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3f5c946a49d8fb35ca00fbc24f8e5bf08a0b0e1a"
      },
      "cell_type": "code",
      "source": "'''Create a boxplot to visualize the strength of association of Survived with Fare. Also calculate biserial correlation.'''\nboxplot_and_correlation(df_train.Survived, df_train.Fare)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a5493e2bdcef45b244d6ed741b1f9eee8f1df298"
      },
      "cell_type": "code",
      "source": "'''So the mean fare of survivors should be much more (positive correlation or boxplot interpretation) than those who died. Calculate mean fare paid by the survivors as well as by the victims.'''\nnume_grouped_by_cat(df_train.Fare, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "82b39be7929c6c247709632aecbed41d906110ab"
      },
      "cell_type": "code",
      "source": "\"\"\"Plot histogram of survivor's vs victims fare.\"\"\"\nnume_hist_by_cat(df_train.Fare, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ed531a3ff6da169cdf04809ffe4f91aeaab9dad8"
      },
      "cell_type": "code",
      "source": "\"\"\"Let's perform ANOVA between Fare and Survived. One can omit this step. I perform just to show how anova is performed if there were more than two groups in our categorical variable.\"\"\"\nanova(df_train.Fare, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2e6445b2d3a57236937d461326b918fec5474385"
      },
      "cell_type": "code",
      "source": "\"\"\"Perform Tukey's test using pairwise_tukeyhsd() function. One can omit Anova and Tukey's test for categorical variable less than three levels by performing biserial correlation.\"\"\"\ntukey_test(df_train.Fare, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ac6277721e18b63d11f4d6971af10c7fcfcdbc6f"
      },
      "cell_type": "code",
      "source": "\"\"\"Let's create a box plot between Age and Survived to have an idea by how much Age is associated with Survived. Also find point biserial correlation between them.\"\"\"\nboxplot_and_correlation(df_train.Survived, df_train.Age)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6111fc439e1d3880066abaa2b38ccc13ce604bc9"
      },
      "cell_type": "code",
      "source": "'''So the mean age of survivors should be just less than those who died (small negative correlation and reading boxplot). Calculate the mean age of survivors and victims.'''\nnume_grouped_by_cat(df_train.Age, df_train.Survived)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4debd4ff29b35d4922622cd29474c65b68b4f384"
      },
      "cell_type": "code",
      "source": "'''Histogram of survivors vs victims age.'''\nnume_hist_by_cat(df_train.Age, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8471ed935d0343bfd00aaf3bed5ecedd4b20456e"
      },
      "cell_type": "code",
      "source": "'''#1.Create a function that calculates absolute and relative frequency of Survived variable by a categorical variable. And then plots the absolute and relative frequency of Survived by a categorical variable.'''\ndef crosstab(cat, cat_target):\n    '''cat = categorical variable, cat_target = our target categorical variable.'''\n    global ax, ax1\n    cat_grouped_by_cat_target = pd.crosstab(index = cat, columns = cat_target)\n    cat_grouped_by_cat_target.rename({0:'Victims', 1:'Survivors'}, axis = 'columns', inplace = True)  # Renaming the columns\n    pct_cat_grouped_by_cat_target = round(pd.crosstab(index = cat, columns = cat_target, normalize = 'index')*100, 2)\n    pct_cat_grouped_by_cat_target.rename({0:'Victims(%)', 1:'Survivors(%)'}, axis = 'columns', inplace = True)\n    print('Survivals and Deaths by', cat.name,':', '\\n',cat_grouped_by_cat_target )\n    print('\\nPercentage Survivals and Deaths by', cat.name, ':','\\n', pct_cat_grouped_by_cat_target)\n    \n    # Plot absolute frequency of Survived by a categorical variable\n    ax =  cat_grouped_by_cat_target.plot.bar(color = ['r', 'g'])\n    plt.title('Survival vs Death Count by %s' %cat.name)\n    abs_bar_labels()\n    plt.show()\n    \n    # Plot relative frequrncy of Survived by a categorical variable\n    ax1 = pct_cat_grouped_by_cat_target.plot.bar(color = ['r', 'g'])\n    plt.title('Percentage Survival vs Death Count by %s' %cat.name)\n    pct_bar_labels()\n    plt.show()\n    \n    '''#2.Create a function to calculate chi_square test between a categorical and target categorical variable.'''\ndef chi_square(cat, cat_target):\n    cat_grouped_by_cat_target = pd.crosstab(index = cat, columns = cat_target)\n    test_result = stats.chi2_contingency (cat_grouped_by_cat_target)\n    print('Chi_square test result between Survived & %s' %cat.name)\n    return display(test_result)\n\n'''#3.Finally create another function to calculate Bonferroni-adjusted pvalue for a categorical and target categorical variable.'''\ndef bonferroni_adjusted(cat, cat_target):\n    dummies = pd.get_dummies(cat)\n    for columns in dummies:\n        crosstab = pd.crosstab(dummies[columns], cat_target)\n        print(stats.chi2_contingency(crosstab))\n    print('\\nColumns:', dummies.columns)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "31bd3dddd3cb27bef1d2481c0dec70f7ee6d06c0"
      },
      "cell_type": "code",
      "source": "'''Count and plot the no of passergers who survived and died due to their sex in absolute and relative scale.'''\ncrosstab(df_train.Sex, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d1b0c3645d6f663e067ef52dfa5f532d12b965a6"
      },
      "cell_type": "code",
      "source": "'''Perform chi-square test of independence between Survived and Sex.'''\nchi_square(df_train.Sex, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "755a4e2f4768d5975641ab049d5bd311a6bdc0ca"
      },
      "cell_type": "code",
      "source": "'''Count and plot the number of passengers who survived and died due to their pclass in absolute and relative scale.'''\ncrosstab(df_train.Pclass, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "154ad6e52834ffac563b473c7bd61fbff7c43edb"
      },
      "cell_type": "code",
      "source": "'''Perform chi-square test of independence between Survived and Pclass.'''\nchi_square(df_train.Pclass, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "59b6f753245836b2543a8c68634afdbb44268b6d"
      },
      "cell_type": "code",
      "source": "'''Calculate Bonferroni-adjusted pvalue for Pclass (1,2,3) and Survived.'''\nbonferroni_adjusted(df_train.Pclass, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4b6144e436fb2d449adb05f01b90ea4d61d744c7"
      },
      "cell_type": "code",
      "source": "'''Count and plot the survivors and victims by place of embarkation in absolute and relative scale.'''\ncrosstab(df_train.Embarked, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "40358f050157d3ec6713076d3bbadaf5516f41f8"
      },
      "cell_type": "code",
      "source": "'''Now perform chi-square test to find the association between Embarked and Survived.'''\nchi_square(df_train.Embarked, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b46b66455edf9fbc2e816b29ce7d92f616384526"
      },
      "cell_type": "code",
      "source": "'''Calculate Bonferroni-adjusted pvalue  between Embarked (C,Q,S one by one) and Survived.'''\nbonferroni_adjusted(df_train.Embarked, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c830e7c9dfd1718d36aa560b81aed4ddc1c52eac"
      },
      "cell_type": "code",
      "source": "'''Count and plot absolute and relative number of survivors and victims due to SibSp.'''\ncrosstab(df_train.SibSp, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d8fea80406c9abd738d543bad8b5a5d2990b6588"
      },
      "cell_type": "code",
      "source": "'''Chi-square test between SibSp and Survived.'''\nchi_square(df_train.SibSp, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f49749e19323a1733678af38739388b7fb3ce69f"
      },
      "cell_type": "code",
      "source": "'''Count and visualize absolute and relative number of survivors and victims by Parch.'''\ncrosstab(df_train.Parch, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "91f904ebbe40c50841c03dabb6a931d51cca85dc"
      },
      "cell_type": "code",
      "source": "'''Perform Chi-square test of independence between Parch and Survived.'''\nchi_square(df_train.Parch, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "70960ca51fb970d0a1b15c99e634cd233e41ed42"
      },
      "cell_type": "code",
      "source": "'''Count and visualize absolute and relative number of survivors and victims by Title.'''\ncrosstab(df_train.Title, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e8f8c061639001626f07e017e490cf5de7113f5f"
      },
      "cell_type": "code",
      "source": "'''Perform Chi-square test of independence between Title and Survived.'''\nchi_square(df_train.Title, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f6f40176c2ad9552b7e91c82f53c0be87023a2a7"
      },
      "cell_type": "code",
      "source": "'''Survivors and victims count and percentage count by Family_size. Also plot the absolute and percentage count.'''\ncrosstab(df_train.Family_size, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e61159621e008cf5b1938ee6a89387e8fa852e18"
      },
      "cell_type": "code",
      "source": "'''Perform Chi-square test of independence between Family_size and Survived.'''\nchi_square(df_train.Family_size, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e4d9a4109e4fcfa15cbbca96e83c7524c007fa10"
      },
      "cell_type": "code",
      "source": "'''Calculate Bonferroni-adjusted pvalue  between Family_size and Survived.'''\nbonferroni_adjusted(df_train.Family_size, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "56d0b39913fc528e5ccefe8c5072e434fcf7dd2e"
      },
      "cell_type": "code",
      "source": "'''Count and plot absolute and relative number of survivors and victims due to Cabin possession.'''\ncrosstab(df_train.Cabin, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9f3036c3785630ae14b48fe29c1dee29121f26a4"
      },
      "cell_type": "code",
      "source": "\"\"\"Perform Chi-square test of independence between Cabin and Survived.\"\"\"\nchi_square(df_train.Cabin, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6e7c7a8c961a242e5b3a0ee82a54d16228721f05"
      },
      "cell_type": "code",
      "source": "'''Count and plot absolute and relative number of survivors and victims due to Ticket category.'''\ncrosstab(df_train.Ticket, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d32c73bdcf0d9652fcfe8fd4f527b0ef5865a39c"
      },
      "cell_type": "code",
      "source": "'''Perform Chi-square test of independence between Ticket and Survived.'''\nchi_square(df_train.Ticket, df_train.Survived)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "92afce31b9c8eeb901ecf5bc077182ab576955b4"
      },
      "cell_type": "code",
      "source": "'''Create a function that plots the impact of 3 predictor variables at a time on a target variable.'''\ndef multivariate_analysis(cat1, cat2, cat3, cat_target):\n    grouped = round(pd.crosstab(index = [cat1, cat2, cat3], columns = cat_target, normalize = 'index')*100, 2)\n    grouped.rename({0:'Died%', 1:'Survived%'}, axis = 1, inplace = True)\n    ax = grouped.plot.bar(color = ['r', 'g'])\n    plt.ylabel('Relative Frequency (%)')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cb85221bffe2b36c8260371ad18ca7482a717b36"
      },
      "cell_type": "code",
      "source": "'''Proportion of survivors and victims due to pclass, sex, and cabin.'''\nmultivariate_analysis(df_train.Pclass, df_train.Sex, df_train.Cabin, df_train.Survived)\nbold('**Sex male seems to be deciding factor for death.**')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c9c07bcd6f43998a2209856d74dee86f8f61b233"
      },
      "cell_type": "code",
      "source": "'''Proportion of survivors and victims due to pclass, sex, and embarked.'''\nmultivariate_analysis(df_train.Pclass, df_train.Sex, df_train.Embarked, df_train.Survived)\nbold('**Again Sex male seems to be deciding factor for death and female for survival.**')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "27827dbb354a248db9ea65737113874e5e455e94"
      },
      "cell_type": "code",
      "source": "'''Proportion of survivors and victims due to pclass, sex, and SibSp.'''\nmultivariate_analysis(df_train.Pclass, df_train.Sex, df_train.SibSp, df_train.Survived)\nbold('**Bigger SibSp and male is responsible more for death.**')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "75ae5b5b43672a5665bb58ed47d63e07f714f633"
      },
      "cell_type": "code",
      "source": "'''Proportion of survivors and victims due to pclass, sex, and Parch.'''\nmultivariate_analysis(df_train.Pclass, df_train.Sex, df_train.Parch, df_train.Survived)\nbold('**Bigger Parch and Sex male is responsible more for death.**')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b8157fe0c63b029e29692bf19fdac69da23cc836"
      },
      "cell_type": "code",
      "source": "'''Proportion of survivors and victims due to pclass, sex, and title.'''\nmultivariate_analysis(df_train.Pclass, df_train.Sex, df_train.Title, df_train.Survived)\nbold('** Passengers with sex male and title mr mostly died.**')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3ef42d2aa6a0df1876a85c986e7388c5ff6026a9"
      },
      "cell_type": "code",
      "source": "'''Proportion of survivors and victims due to pclass, sex, and family_size.'''\nmultivariate_analysis(df_train.Pclass, df_train.Sex, df_train.Family_size, df_train.Survived)\nbold('** Sex male, family_size single and large greatly influence the death ratio.**')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b2276fce1f92ed4bb8581a413eb1166388446c4b"
      },
      "cell_type": "code",
      "source": "'''Proportion of survivors and victims due to pclass, sex, and Ticket category.'''\nmultivariate_analysis(df_train.Pclass, df_train.Sex, df_train.Ticket, df_train.Survived)\nbold('**Sex female, ticket p and w mostly survived.**')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fe5f78fcd12dcb8130516950fc0088a0d99c5e0c"
      },
      "cell_type": "code",
      "source": "'''Proportion of survivors and victims due to pclass, title, and cabin.'''\nmultivariate_analysis(df_train.Pclass, df_train.Title, df_train.Cabin, df_train.Survived)\nbold('**Title mrs, master and cabin x had best survival ratio.**')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "720806b0ea040ec47a7d857ab2d90ce2d2ea240d"
      },
      "cell_type": "code",
      "source": "'''Proportion of survivors and victims due to family_size, sex, and cabin.'''\nmultivariate_analysis(df_train.Family_size, df_train.Sex, df_train.Cabin, df_train.Survived)\nbold('**Family_size small, medium and sex female had best survival chance.**')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6d00962de5f40ad4a915a07ca76e5186612b9ea0"
      },
      "cell_type": "code",
      "source": "'''Proportion of survivors and victims due to sex, title, and family_size.'''\nmultivariate_analysis(df_train.Sex, df_train.Title, df_train.Family_size, df_train.Survived)\nbold('**Title aristocrat, sex female and family_size small mostly survived.**')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9c356aa1394adefaa8a6a7af2faddce67d5faf66"
      },
      "cell_type": "code",
      "source": "'''Proportion of survivors and victims due to sex, title, and cabin.'''\nmultivariate_analysis(df_train.Sex, df_train.Title, df_train.Cabin, df_train.Survived)\nbold('**Title aristocrat, miss, mrs and sex female mostly survived.**')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f4fb98baf6241cdce6f33a9b15ae127df290bb9a"
      },
      "cell_type": "code",
      "source": "'''Proportion of survivors and victims due to sex, title, and embarked.'''\nmultivariate_analysis(df_train.Sex, df_train.Title, df_train.Embarked, df_train.Survived)\nbold('**Embarked c, sex female and title master and aristocrat had best survival rate.**')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1e153b82c9e56496a5c24aecbf8284ad20eca68a"
      },
      "cell_type": "code",
      "source": "\"\"\"Proportion of survivors and victims due to sex, title, and Ticket.\"\"\"\nmultivariate_analysis(df_train.Sex, df_train.Title, df_train.Ticket, df_train.Survived)\nbold('**Ticker n, w and sex male and title mr mostly died.**')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9e2deabd4be9574a08fa44f0095ee5e6755d64ae"
      },
      "cell_type": "code",
      "source": "'''Create bin categories for Age.'''\nlabel_names = ['infant','child','teenager','young_adult','adult','aged']\n\n'''Create range for each bin categories of Age.'''\ncut_points = [0,5,12,18,35,60,81]\n\n'''Create and view categorized Age with original Age.'''\nmerged['Age_binned'] = pd.cut(merged.Age, cut_points, labels = label_names)\ndisplay(merged[['Age', 'Age_binned']].head())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6e088194931d7089e2efe779a30f345a54933e24"
      },
      "cell_type": "code",
      "source": "'''Create bin categories for Fare.'''\ngroups = ['low','medium','high','very_high']\n\n'''Create range for each bin categories of Fare.'''\ncut_points = [-1, 130, 260, 390, 520]\n\n'''Create and view categorized Fare with original Fare.'''\nmerged['Fare_binned'] = pd.cut(merged.Fare, cut_points, labels = groups)\ndisplay(merged[['Fare', 'Fare_binned']].head(2))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b2a0a2c6eea63c9e0fa0e698b010dbb9edcdca81"
      },
      "cell_type": "code",
      "source": "\"\"\"Let's see all the variables we currently have with their category.\"\"\"\ndisplay(merged.head(2))\n\n'''Drop the features that would not be useful anymore.'''\nmerged.drop(columns = ['Name', 'Age', 'Fare'], inplace = True, axis = 1)\n\n'''Features after dropping.'''\nbold('**Features remaining after dropping:**')\ndisplay(merged.columns)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5ef1f8e2cb62a8c5cd3fe3fe6c645bbf31d55000"
      },
      "cell_type": "code",
      "source": "'''Checking current data types.'''\nbold('**Current variable Data Types:**')\ndisplay(merged.dtypes)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0bc5eb9818f1702971cc64c744002aaa0d9f2ae2"
      },
      "cell_type": "code",
      "source": "'''Correcting data types, converting into categorical variables.'''\nmerged.loc[:, ['Pclass', 'Sex', 'Embarked', 'Cabin', 'Title', 'Family_size', 'Ticket']] = merged.loc[:, ['Pclass', 'Sex', 'Embarked', 'Cabin', 'Title', 'Family_size', 'Ticket']].astype('category')\n\n'''Due to merging there are NaN values in Survived for test set observations.'''\nmerged.Survived = merged.Survived.dropna().astype('int')#Converting without dropping NaN throws an error.\n\n'''Check if data types have been corrected.'''\nbold('**Data types after correction:**')\ndisplay(merged.dtypes)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "204d8699f0764626965eab741dbdf1c165e97782"
      },
      "cell_type": "code",
      "source": "'''Convert categorical data into numeric to feed our machine learning model.'''\nmerged = pd.get_dummies(merged)\n\n\"\"\"Let's visualize the updated dataset.\"\"\"\ndisplay(merged.head(2))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c5b10f0117e77ab5d8eae8d3ae1d39fa414c4540"
      },
      "cell_type": "code",
      "source": "\"\"\"Let's split the train and test set to feed machine learning algorithm.\"\"\"\ndf_train = merged.iloc[:891, :]\ndf_test  = merged.iloc[891:, :]\n\n'''Drop passengerid from train set and Survived from test set.'''\ndf_train = df_train.drop(columns = ['PassengerId'], axis = 1)\ndf_test = df_test.drop(columns = ['Survived'], axis = 1)\n\n'''Extract data sets as input and output for machine learning models.'''\nX_train = df_train.drop(['Survived'], axis = 1) # Input matrix as pandas dataframe (dim:891*47).\ny_train = df_train['Survived'] #Output vector as pandas series (dim:891*1)\n\n\"\"\"Extract test set\"\"\"\nX_test  = df_test.drop(\"PassengerId\", axis = 1).copy()\n\n'''See the dimensions of input and output data set.'''\ndisplay(X_train.shape, X_test.shape, y_train.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0219a50f612245be1f79eba9caea4f11d9dae61c"
      },
      "cell_type": "code",
      "source": "'''#1.Create a function that returns train accuracy of different models.'''\ndef train_accuracy(model):\n        model.fit(X_train, y_train)\n        train_accuracy = model.score(X_train, y_train)\n        return train_accuracy\n'''#2.Create another function that returns mean cross validation score for different models.'''\ndef x_val_score(model):\n    from sklearn.model_selection import cross_val_score\n    x_val_score = cross_val_score(model, X_train, y_train, cv = 10, scoring = 'accuracy').mean()\n    return x_val_score\n\n'''#3.Create a function to tune hyperparameters of the selected models.'''\ndef tune_hyperparameters(model, params):\n    from sklearn.model_selection import GridSearchCV\n    global best_params, best_score\n    # Construct grid search object with 10 fold cross validation.\n    grid = GridSearchCV(model, params, verbose = 2, cv = 10, scoring = 'accuracy', n_jobs = -1)\n    # Fit using grid search.\n    grid.fit(X_train, y_train)\n    best_params, best_score = grid.best_params_, grid.best_score_\n    return best_params, best_score\n\n'''#4.Create a function that compares cross validation scores with tunned scores for different models by plotting them.'''\ndef compare_scores(accuracy):\n    global ax1    \n    ax1 = accuracy.plot.bar(legend = False, color = ['rosybrown'])\n    # Removes square brackets and quotes from column name after converting list.\n    plt.title('Models %s' % ''.join(list(accuracy.columns)))\n    pct_bar_labels()\n    plt.ylabel('% Accuracy')\n    plt.show()\n    \n    '''#5.Create a function that plot feature importance by the best selected models.'''\ndef plot_feature_importance(model):\n    importance = pd.DataFrame({'Feature_name': X_train.columns,\n                              'Importance': np.round(model.feature_importances_,3)})\n    importance = importance.sort_values(by = 'Importance', ascending = False).set_index('Feature_name')\n    importance.plot.bar(legend = False, color = ['brown'])\n         \n'''#6.This function plots leanring curves for different models.'''\ndef plot_learning_curve(model):\n    from sklearn.model_selection import learning_curve\n    # Create feature matrix and target vector\n    X, y = X_train, y_train\n    # Create CV training and test scores for various training set sizes\n    train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv = 10, \n                                                    scoring='accuracy', n_jobs = -1, \n                                                    train_sizes = np.linspace(0.01, 1.0, 17))\n                                                    # 17 different sizes of the training set\n\n    # Create means and standard deviations of training set scores\n    train_mean = np.mean(train_scores, axis = 1)\n    train_std = np.std(train_scores, axis = 1)\n\n    # Create means and standard deviations of test set scores\n    test_mean = np.mean(test_scores, axis = 1)\n    test_std = np.std(test_scores, axis = 1)\n\n    # Draw lines\n    plt.plot(train_sizes, train_mean, 'o-', color = 'red',  label = 'Training score')\n    plt.plot(train_sizes, test_mean, 'o-', color = 'green', label = 'Cross-validation score')\n    # Draw bands\n    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha = 0.1, color = 'r') # Alpha controls band transparency.\n    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha = 0.1, color = 'g')\n\n    # Create plot\n    plt.xlabel('Training Set Size')\n    plt.ylabel('Accuracy Score') \n    plt.legend(loc = 'best')\n    plt.grid()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a3287bb00baa53e3b45dfcc522f88733b019ed73"
      },
      "cell_type": "code",
      "source": "\"\"\"Building machine learning models: \nWe will try 7 different classifiers to find the best classifier after tunning model's hyperparameters that will best generalize the unseen(test) data.\"\"\"\n\n'''#1.Logistic Regression'''\nfrom sklearn.linear_model import LogisticRegression\nlr_train_accuracy = train_accuracy(LogisticRegression())\n\n'''#2.Support Vector Machines'''\nfrom sklearn.svm import SVC\nsvm_train_accuracy = train_accuracy(SVC(gamma = 'auto'))\n\n'''#3.Random Forest Classifier'''\nfrom sklearn.ensemble import RandomForestClassifier\nrf_train_accuracy = train_accuracy(RandomForestClassifier(random_state = 43, n_estimators = 100))\n\n'''#4.KNN'''\nfrom sklearn.neighbors import KNeighborsClassifier\nknn_train_accuracy = train_accuracy(KNeighborsClassifier())\n\n'''#5.Gaussian Naive Bayes'''\nfrom sklearn.naive_bayes import  GaussianNB\ngnb_train_accuracy = train_accuracy(GaussianNB())\n\n'''#6.Decision Tree Classifier'''\nfrom sklearn.tree import DecisionTreeClassifier\ndt_train_accuracy = train_accuracy(DecisionTreeClassifier(random_state = 43))\n\n'''#7.Gradient Boosting Classifier'''\nfrom sklearn.ensemble import GradientBoostingClassifier\ngbc_train_accuracy = train_accuracy(GradientBoostingClassifier(random_state = 43))\n\n'''Models with best training accuracy:'''\ntrain_accuracy = round(pd.DataFrame({'Train_accuracy(%)':[lr_train_accuracy, svm_train_accuracy, rf_train_accuracy, knn_train_accuracy, gnb_train_accuracy, dt_train_accuracy, gbc_train_accuracy]})*100, 2)\ntrain_accuracy.index = ['LR', 'SVC', 'RF', 'KNN', 'GNB', 'DT', 'GBC']\nsorted_train_accuracy = train_accuracy.sort_values(by = 'Train_accuracy(%)', ascending = False) \ndisplay(sorted_train_accuracy)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0d40c66f66089bc7bfeef48521daa776f59fcfd7"
      },
      "cell_type": "code",
      "source": "\"\"\"Let's perform k-fold cross validation to find the best classifier with the best cross validation accuracy that will best generalize the previously unseen data.\"\"\"\nlr_x_val_score  = x_val_score(LogisticRegression())\nsvc_x_val_score = x_val_score(SVC(gamma = 'auto'))\nrf_x_val_score  = x_val_score(RandomForestClassifier(random_state = 47, n_estimators = 100))\nknn_x_val_score = x_val_score(KNeighborsClassifier())\ngnb_x_val_score = x_val_score(GaussianNB())\ndt_x_val_score  = x_val_score(DecisionTreeClassifier(random_state = 43))\ngbc_x_val_score = x_val_score(GradientBoostingClassifier(random_state = 43))\n\n'''Models with best cross validation score:'''\nx_val_score = round(pd.DataFrame({'X_val_score(%)':[lr_x_val_score, svc_x_val_score, rf_x_val_score, knn_x_val_score, gnb_x_val_score, dt_x_val_score, gbc_x_val_score]})*100, 2)\nx_val_score.index = ['LR', 'SVC', 'RF', 'KNN', 'GNB', 'DT', 'GBC']\nsorted_x_val_score = x_val_score.sort_values(by = 'X_val_score(%)', ascending = False) \ndisplay(sorted_x_val_score)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c15b389510fad7897f640605e4c55b73a10ac1ae"
      },
      "cell_type": "code",
      "source": "\"\"\"Define all the models' hyperparameters one by one first::\"\"\"\n\n'''Define hyperparameters the logistic regression will be tuned with. For LR, the following hyperparameters are usually tunned.'''\nlr_params = {'penalty':['l1', 'l2'],\n             'C': np.logspace(0, 4, 10)}\n\n'''For GBC, the following hyperparameters are usually tunned.'''\ngbc_params = {'learning_rate': [0.01, 0.02, 0.05, 0.01],\n              'max_depth': [4, 6, 8],\n              'max_features': [1.0, 0.3, 0.1], \n              'min_samples_split': [ 2, 3, 4],\n              'random_state':[43]}\n\n'''For SVC, the following hyperparameters are usually tunned.'''\nsvc_params = {'C': [6,7,8,9,10,11,12], \n              'kernel': ['linear','rbf'],\n              'gamma': [0.5,0.2,0.1, 0.001, 0.0001]}\n\n'''For DT, the following hyperparameters are usually tunned.'''\ndt_params = {'max_features': ['auto', 'sqrt', 'log2'],\n             'min_samples_split': [2,3,4,5,6,7,8,9,10,11,12,13,14,15], \n             'min_samples_leaf':[1,2,3,4,5,6,7,8,9,10,11],\n             'random_state':[43]}\n\n'''For RF, the following hyperparameters are usually tunned.'''\nrf_params = {'criterion':['gini','entropy'],\n             'n_estimators':[10,15,20,25,30],\n             'min_samples_leaf':[1,2,3],\n             'min_samples_split':[3,4,5,6,7], \n             'max_features':['sqrt', 'auto', 'log2'],\n             'random_state':[44]}\n\n'''For KNN, the following hyperparameters are usually tunned.'''\nknn_params = {'n_neighbors':[5,6,7,8,9,10],\n              'leaf_size':[1,2,3,5],\n              'weights':['uniform', 'distance'],\n              'algorithm':['auto', 'ball_tree','kd_tree','brute']}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f48e7a66aac4de530404c3c26b6465950ea7e67e"
      },
      "cell_type": "code",
      "source": "'''Tune LR hyperparameters.'''\ntune_hyperparameters(LogisticRegression(), params = lr_params)\nlr_best_params, lr_best_score = best_params, best_score\nprint('Best score:', lr_best_score)\nprint('Best parameters:', lr_best_params)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b9d3d87396e663730acb9931cc6ac5cfbbc7f1a6"
      },
      "cell_type": "code",
      "source": "\"\"\"Tune GBC's hyperparameters.\"\"\"\ntune_hyperparameters(GradientBoostingClassifier(), params = gbc_params)\ngbc_best_score, gbc_best_params = best_score, best_params",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "189aff5a02a2f9631180c7ceb587469f149908f7"
      },
      "cell_type": "code",
      "source": "\"\"\"Tune SVC's hyperparameters.\"\"\"\ntune_hyperparameters(SVC(), params = svc_params)\nsvc_best_score, svc_best_params = best_score, best_params",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7dd2745c92eda727c9e4c1b16345723612af0b6d"
      },
      "cell_type": "code",
      "source": "\"\"\"Tune DT's hyperparameters.\"\"\"\ntune_hyperparameters(DecisionTreeClassifier(), params = dt_params)\ndt_best_score, dt_best_params = best_score, best_params\nignore_warnings()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "26ece267c7592b2162361142eaa5265b30794995"
      },
      "cell_type": "code",
      "source": "\"\"\"Tune RF's hyperparameters.\"\"\"\ntune_hyperparameters(RandomForestClassifier(), params = rf_params)\nrf_best_score, rf_best_params = best_score, best_params\nignore_warnings()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9d167397c586afe7d02f79dea542325d48161619"
      },
      "cell_type": "code",
      "source": "\"\"\"Tune KNN's hyperparameters.\"\"\"\ntune_hyperparameters(KNeighborsClassifier(), params = knn_params)\nknn_best_score, knn_best_params = best_score, best_params",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dacf467bc46237fd90ecdefc64642bf7c16cc38c"
      },
      "cell_type": "code",
      "source": "'''Create a dataframe of tunned scores and sort them in descending order.'''\ntunned_scores = round(pd.DataFrame({'Tunned_accuracy(%)': [lr_best_score, gbc_best_score, svc_best_score, dt_best_score, rf_best_score, knn_best_score]})*100,2)\ntunned_scores.index = ['LR', 'GBC', 'SVC', 'DT', 'RF', 'KNN']\nsorted_tunned_scores = tunned_scores.sort_values(by = 'Tunned_accuracy(%)', ascending = False)\ndisplay(sorted_tunned_scores)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2f03610ba59e4bbbb3c6f257a41e255e2f66c0df"
      },
      "cell_type": "code",
      "source": "'''Compare cross validation scores with tunned scores to find the best model.'''\ncompare_scores(sorted_x_val_score)\ncompare_scores(sorted_tunned_scores)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "83040c31f0200c2e4288617332bc6ae33c13091d"
      },
      "cell_type": "code",
      "source": "\"\"\"Train and predict using rf's best hyperparameters.\"\"\"\nrf = RandomForestClassifier(**rf_best_params)\nrf.fit(X_train, y_train)\ny_pred_rf_tunned = rf.predict(X_test)\n\n\"\"\"Train and predict using gbc's best hyperparameters.\"\"\"\ngbc = GradientBoostingClassifier(**gbc_best_params)\ngbc.fit(X_train, y_train)\ny_pred_gbc_tunned = gbc.predict(X_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ed56bf68e61fb8fd4d980ca21a9405bb4b6467f5"
      },
      "cell_type": "code",
      "source": "'''Plot feature importance by rf and gbc.'''\nplot_feature_importance(rf)\nplt.title('RF Feature Importance')\nplt.show()\n\nplot_feature_importance(gbc)\nplt.title('GBC Feature Importance')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4ca83ea1251fea2ba93659d6759b89d01842d45b"
      },
      "cell_type": "code",
      "source": "'''Plot learning curves of best rf classifier.'''\nplot_learning_curve(rf)\nplt.title('Learning Curve of Tunned Random Forest')\nplt.show()\n\n'''Plot learning curve of best gbc.'''\nplot_learning_curve(gbc)\nplt.title('Learning Curve of Tunned Gradient Boosting')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cc4b335341dacebf793078ba2794021ba35f565a"
      },
      "cell_type": "code",
      "source": "'''Return prediction to use it in another function.'''\ndef x_val_predict(model):\n    from sklearn.model_selection import cross_val_predict\n    predicted = cross_val_predict(model, X_train, y_train, cv = 10)\n    return predicted # Now we can use it in another function by assigning the function to its return value.\n\n'''#1.Confusion matrix.'''\ndef confusion_matrix(model):\n    predicted = x_val_predict(model)\n    confusion_matrix = pd.crosstab(y_train, predicted, rownames = ['Actual'], colnames = ['Predicted/Classified'], margins = True) # We use pandas crosstab\n    return display(confusion_matrix)\n'''#2.Precision score.'''\ndef precision_score(model):\n    from sklearn.metrics import precision_score\n    predicted = x_val_predict(model)\n    precision_score = precision_score(y_train, predicted)\n    return display(precision_score)\n\n'''#3.Recall score.'''\ndef recall_score(model):\n    from sklearn.metrics import recall_score\n    predicted = x_val_predict(model)\n    recall_score = recall_score(y_train, predicted)\n    return display(recall_score) \n\n'''#4.Specificity score.'''\ndef specificity_score(model):\n    from sklearn.metrics import confusion_matrix\n    predicted = x_val_predict(model)\n    tn, fp, fn, tp = confusion_matrix(y_train, predicted).ravel()\n    specificity_score = tn / (tn + fp)\n    return display(specificity_score)\n\n'''#5.F1 score.'''\ndef f1_score(model):\n    from sklearn.metrics import f1_score\n    predicted = x_val_predict(model)\n    f1_score = f1_score(y_train, predicted)\n    return display(f1_score)\n\n'''#6.Classification report.'''\ndef classification_report(model):\n    from sklearn.metrics import classification_report\n    predicted = x_val_predict(model)\n    classification_report = classification_report(y_train, predicted)\n    return print(classification_report)\n\n'''#7.Plot precision-recall vs threshold curve.'''\ndef precision_recall_vs_threshold(model):\n    from sklearn.metrics import precision_recall_curve\n    probablity = model.predict_proba(X_train)[:, 1]\n    precision, recall, threshold = precision_recall_curve(y_train, probablity)\n    plt.figure(figsize = (18, 4))\n    plt.plot(threshold, precision[:-1], 'b-', label = 'precision', lw = 3.7)\n    plt.plot(threshold, recall[:-1], 'g', label = 'recall', lw = 3.7)\n    plt.xlabel('Threshold')\n    plt.legend(loc = 'best')\n    plt.ylim([0, 1])\n    \n'''#8.Plot recall vs precision curve.'''\ndef plot_precision_vs_recall(model):\n    from sklearn.metrics import precision_recall_curve\n    probablity = model.predict_proba(X_train)[:, 1]\n    precision, recall, threshold = precision_recall_curve(y_train, probablity)\n    plt.figure(figsize = (18, 5))\n    plt.plot(recall, precision, 'r-', lw = 3.7)\n    plt.ylabel('Recall')\n    plt.xlabel('Precision')\n    plt.axis([0, 1.5, 0, 1.5])\n    \n    '''#9.Plot ROC curve with AUC score.'''\ndef plot_roc_and_auc_score(model):\n    from sklearn.metrics import roc_curve, roc_auc_score\n    probablity = model.predict_proba(X_train)[:, 1]\n    false_positive_rate, true_positive_rate, threshold = roc_curve(y_train, probablity)\n    auc_score = roc_auc_score(y_train, probablity)\n    plt.figure(figsize = (18, 5))\n    plt.plot(false_positive_rate, true_positive_rate, label = \"ROC CURVE, AREA = \"+ str(auc_score))\n    plt.plot([0, 1], [0, 1], 'black', lw = 3.7)\n    plt.xlabel('False Positive Rate (1-Specificity)')\n    plt.ylabel('True Positive Rate (Sensitivity)')\n    plt.axis([0, 1, 0, 1])\n    plt.legend(loc = 4)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1a92e48f61f96edfc88fa627dac8d42a36835ab0"
      },
      "cell_type": "code",
      "source": "'''Calculate confusion matrix of rf and gbc.'''\nconfusion_matrix(rf)\nconfusion_matrix(gbc)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b1cd9936d8c45b4d0fe198a51db4f05b500bb7ad"
      },
      "cell_type": "code",
      "source": "'''Compute precision score for rf and gbc.'''\nprecision_score(rf)\nprecision_score(gbc)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "306714b32985dbe60c95cb45223fd34b6e203e50"
      },
      "cell_type": "code",
      "source": "'''Compute recall score for rf and gbc.'''\nrecall_score(rf)\nrecall_score(gbc)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c051871b516855a45f74142f9dd56b72ff780758"
      },
      "cell_type": "code",
      "source": "'''Calculate specificity score for rf and gbc.'''\nspecificity_score(rf)\nspecificity_score(gbc)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5224e6745884837749200f76994f1d6846558bad"
      },
      "cell_type": "code",
      "source": "'''Calculate f1 score for rf and gbc.'''\nf1_score(rf)\nf1_score(gbc)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "818678c6188fa0d0e29825be833719842cc0537e"
      },
      "cell_type": "code",
      "source": "'''Calculate classification report for rf and gbc.'''\nclassification_report(rf)\nclassification_report(gbc)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9e1ba34b7037f3214bcd31387d9d91ef1c20a5fd"
      },
      "cell_type": "code",
      "source": "'''Plot precision-recall vs threshold curve for rf and gbc.'''\nprecision_recall_vs_threshold(rf)\nplt.title('RF Precision-Recall vs Threshold Curve')\nplt.show()\n\nprecision_recall_vs_threshold(gbc)\nplt.title('GBC Precision-Recall vs Threshold Curve')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "903538d60f17712a01ee7701604b16cd3627c134"
      },
      "cell_type": "code",
      "source": "'''Plot recall vs precision curve of rf and gbc.'''\nplot_precision_vs_recall(rf)\nplt.title('RF Precision-Recall Curve' )\nplt.show()\n\nplot_precision_vs_recall(gbc)\nplt.title('GBC Precision-Recall Curve' )\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "84c45f8f48d23d3c44eaafe3ca1a8e3864f92b88"
      },
      "cell_type": "code",
      "source": "'''Plot roc curve and auc score for rf and gbc.'''\nplot_roc_and_auc_score(rf)\nplt.title('RF ROC Curve with AUC Score')\nplt.show()\n\nplot_roc_and_auc_score(gbc)\nplt.title('GBC ROC Curve with AUC Score')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b119cac4c7cbfb03d827bc2d733dbe027b828d1d"
      },
      "cell_type": "code",
      "source": "'''Submission with the most accurate random forest classifier.'''\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": y_pred_rf_tunned})\nsubmission.to_csv('submission_rf.csv', index = False)\n\n\n'''Submission with the most accurate gradient boosting classifier.'''\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": y_pred_gbc_tunned})\nsubmission.to_csv('submission_gbc.csv', index = False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}